{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"word_freq_make\",         \n",
    "  \"word_freq_address\",\n",
    "  \"word_freq_all\",          \n",
    "  \"word_freq_3d\",           \n",
    "  \"word_freq_our\",          \n",
    "  \"word_freq_over\",         \n",
    "  \"word_freq_remove\",       \n",
    "  \"word_freq_internet\",     \n",
    "  \"word_freq_order\",        \n",
    "  \"word_freq_mail\",         \n",
    "  \"word_freq_receive\",      \n",
    "  \"word_freq_will\",         \n",
    "  \"word_freq_people\",       \n",
    "  \"word_freq_report\",       \n",
    "  \"word_freq_addresses\",    \n",
    "  \"word_freq_free\",         \n",
    "  \"word_freq_business\",\n",
    "  \"word_freq_email\",        \n",
    "  \"word_freq_you\",          \n",
    "  \"word_freq_credit\",       \n",
    "  \"word_freq_your\",         \n",
    "  \"word_freq_font\",         \n",
    "  \"word_freq_000\",          \n",
    "  \"word_freq_money\",        \n",
    "  \"word_freq_hp\",           \n",
    "  \"word_freq_hpl\",          \n",
    "  \"word_freq_george\",       \n",
    "  \"word_freq_650\",          \n",
    "  \"word_freq_lab\",          \n",
    "  \"word_freq_labs\",         \n",
    "  \"word_freq_telnet\",       \n",
    "  \"word_freq_857\",          \n",
    "  \"word_freq_data\",         \n",
    "  \"word_freq_415\",          \n",
    "  \"word_freq_85\",           \n",
    "  \"word_freq_technology\",   \n",
    "  \"word_freq_1999\",         \n",
    "  \"word_freq_parts\",        \n",
    "  \"word_freq_pm\",           \n",
    "  \"word_freq_direct\",       \n",
    "  \"word_freq_cs\",           \n",
    "  \"word_freq_meeting\",      \n",
    "  \"word_freq_original\",     \n",
    "  \"word_freq_project\",      \n",
    "  \"word_freq_re\",           \n",
    "  \"word_freq_edu\",          \n",
    "  \"word_freq_table\",        \n",
    "  \"word_freq_conference\",   \n",
    "  \"char_freq_comma\",            \n",
    "  \"char_freq_parentheses\",            \n",
    "  \"char_freq_key\",            \n",
    "  \"char_freq_exclamation\",\n",
    "  \"char_freq_dollar\",            \n",
    "  \"char_freq_hashtag\",            \n",
    "  \"capital_run_length_average\",\n",
    "  \"capital_run_length_longest\", \n",
    "  \"capital_run_length_total\",\n",
    "  \"spam\"]\n",
    "wd = \"C:/Users/marco/Desktop/Estatistica/Semestres/Semestre 8/Tópicos em Estatística 1 (Deep Learning)/Trabalho/\"\n",
    "data = pd.read_csv(wd + 'spambase.data', names = cols)\n",
    "X = data.loc[:, data.columns != 'spam']\n",
    "y = data.spam\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scale = scaler.fit_transform(train_X)\n",
    "val_X_scale = scaler.fit_transform(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.7908 - accuracy: 0.4893\n",
      "Epoch 2/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.6347 - accuracy: 0.6139\n",
      "Epoch 3/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.7078\n",
      "Epoch 4/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.4764 - accuracy: 0.7757\n",
      "Epoch 5/150\n",
      "54/54 [==============================] - 0s 960us/step - loss: 0.4248 - accuracy: 0.8142\n",
      "Epoch 6/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3832 - accuracy: 0.8429\n",
      "Epoch 7/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8632\n",
      "Epoch 8/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3241 - accuracy: 0.8794\n",
      "Epoch 9/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3037 - accuracy: 0.8896\n",
      "Epoch 10/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.8980\n",
      "Epoch 11/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2730 - accuracy: 0.9017\n",
      "Epoch 12/150\n",
      "54/54 [==============================] - 0s 942us/step - loss: 0.2614 - accuracy: 0.9064\n",
      "Epoch 13/150\n",
      "54/54 [==============================] - 0s 923us/step - loss: 0.2517 - accuracy: 0.9101\n",
      "Epoch 14/150\n",
      "54/54 [==============================] - 0s 960us/step - loss: 0.2438 - accuracy: 0.9136\n",
      "Epoch 15/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2368 - accuracy: 0.9148\n",
      "Epoch 16/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9165\n",
      "Epoch 17/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9183\n",
      "Epoch 18/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.9200\n",
      "Epoch 19/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2171 - accuracy: 0.9203\n",
      "Epoch 20/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2135 - accuracy: 0.9209\n",
      "Epoch 21/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.9223\n",
      "Epoch 22/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9235\n",
      "Epoch 23/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9235\n",
      "Epoch 24/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.9270\n",
      "Epoch 25/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.9275\n",
      "Epoch 26/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.9281\n",
      "Epoch 27/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.9296\n",
      "Epoch 28/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.9301\n",
      "Epoch 29/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.9310\n",
      "Epoch 30/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9316\n",
      "Epoch 31/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.9325\n",
      "Epoch 32/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.9313\n",
      "Epoch 33/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9322\n",
      "Epoch 34/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.9316\n",
      "Epoch 35/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.9319\n",
      "Epoch 36/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.9328\n",
      "Epoch 37/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.9316\n",
      "Epoch 38/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.9322\n",
      "Epoch 39/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.9328\n",
      "Epoch 40/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.9336\n",
      "Epoch 41/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.9339\n",
      "Epoch 42/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.9351\n",
      "Epoch 43/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1731 - accuracy: 0.9351\n",
      "Epoch 44/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1722 - accuracy: 0.9348\n",
      "Epoch 45/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1711 - accuracy: 0.9357\n",
      "Epoch 46/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1701 - accuracy: 0.9354\n",
      "Epoch 47/150\n",
      "54/54 [==============================] - 0s 942us/step - loss: 0.1693 - accuracy: 0.9348\n",
      "Epoch 48/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1687 - accuracy: 0.9354\n",
      "Epoch 49/150\n",
      "54/54 [==============================] - 0s 924us/step - loss: 0.1676 - accuracy: 0.9362\n",
      "Epoch 50/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.1669 - accuracy: 0.9357\n",
      "Epoch 51/150\n",
      "54/54 [==============================] - 0s 897us/step - loss: 0.1662 - accuracy: 0.9359\n",
      "Epoch 52/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.9368\n",
      "Epoch 53/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1649 - accuracy: 0.9365\n",
      "Epoch 54/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9362\n",
      "Epoch 55/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.1636 - accuracy: 0.9377\n",
      "Epoch 56/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1629 - accuracy: 0.9374\n",
      "Epoch 57/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1622 - accuracy: 0.9377\n",
      "Epoch 58/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9365\n",
      "Epoch 59/150\n",
      "54/54 [==============================] - 0s 988us/step - loss: 0.1611 - accuracy: 0.9380\n",
      "Epoch 60/150\n",
      "54/54 [==============================] - 0s 960us/step - loss: 0.1607 - accuracy: 0.9357\n",
      "Epoch 61/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.9357\n",
      "Epoch 62/150\n",
      "54/54 [==============================] - 0s 923us/step - loss: 0.1593 - accuracy: 0.9362\n",
      "Epoch 63/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9362\n",
      "Epoch 64/150\n",
      "54/54 [==============================] - 0s 960us/step - loss: 0.1584 - accuracy: 0.9362\n",
      "Epoch 65/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9371\n",
      "Epoch 66/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9362\n",
      "Epoch 67/150\n",
      "54/54 [==============================] - 0s 923us/step - loss: 0.1569 - accuracy: 0.9374\n",
      "Epoch 68/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9371\n",
      "Epoch 69/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9368\n",
      "Epoch 70/150\n",
      "54/54 [==============================] - 0s 997us/step - loss: 0.1553 - accuracy: 0.9374\n",
      "Epoch 71/150\n",
      "54/54 [==============================] - 0s 887us/step - loss: 0.1550 - accuracy: 0.9377\n",
      "Epoch 72/150\n",
      "54/54 [==============================] - 0s 887us/step - loss: 0.1545 - accuracy: 0.9374\n",
      "Epoch 73/150\n",
      "54/54 [==============================] - 0s 960us/step - loss: 0.1540 - accuracy: 0.9377\n",
      "Epoch 74/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9383\n",
      "Epoch 75/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.9380\n",
      "Epoch 76/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.9388\n",
      "Epoch 77/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9388\n",
      "Epoch 78/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9386\n",
      "Epoch 79/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9391\n",
      "Epoch 80/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1507 - accuracy: 0.9394\n",
      "Epoch 81/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9394\n",
      "Epoch 82/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9391\n",
      "Epoch 83/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9397\n",
      "Epoch 84/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.9403\n",
      "Epoch 85/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9397\n",
      "Epoch 86/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9397\n",
      "Epoch 87/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9397\n",
      "Epoch 88/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.9400\n",
      "Epoch 89/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.9412\n",
      "Epoch 90/150\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1470 - accuracy: 0.9403\n",
      "Epoch 91/150\n",
      "54/54 [==============================] - 0s 923us/step - loss: 0.1469 - accuracy: 0.9409\n",
      "Epoch 92/150\n",
      "54/54 [==============================] - 0s 923us/step - loss: 0.1464 - accuracy: 0.9406\n",
      "Epoch 93/150\n",
      "54/54 [==============================] - 0s 960us/step - loss: 0.1462 - accuracy: 0.9406\n",
      "Epoch 94/150\n",
      "54/54 [==============================] - 0s 997us/step - loss: 0.1459 - accuracy: 0.9417\n",
      "Epoch 95/150\n",
      "54/54 [==============================] - 0s 886us/step - loss: 0.1459 - accuracy: 0.9426\n",
      "Epoch 96/150\n",
      "54/54 [==============================] - 0s 979us/step - loss: 0.1456 - accuracy: 0.9412\n",
      "Epoch 97/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1453 - accuracy: 0.9417\n",
      "Epoch 98/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1449 - accuracy: 0.9420\n",
      "Epoch 99/150\n",
      "54/54 [==============================] - 0s 979us/step - loss: 0.1448 - accuracy: 0.9417\n",
      "Epoch 100/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1445 - accuracy: 0.9420\n",
      "Epoch 101/150\n",
      "54/54 [==============================] - 0s 997us/step - loss: 0.1443 - accuracy: 0.9429\n",
      "Epoch 102/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1442 - accuracy: 0.9423\n",
      "Epoch 103/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9429: 0s - loss: 0.1417 - accuracy: 0.94\n",
      "Epoch 104/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9417\n",
      "Epoch 105/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9432\n",
      "Epoch 106/150\n",
      "54/54 [==============================] - 0s 887us/step - loss: 0.1429 - accuracy: 0.9438\n",
      "Epoch 107/150\n",
      "54/54 [==============================] - 0s 868us/step - loss: 0.1430 - accuracy: 0.9420\n",
      "Epoch 108/150\n",
      "54/54 [==============================] - 0s 960us/step - loss: 0.1427 - accuracy: 0.9435\n",
      "Epoch 109/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1423 - accuracy: 0.9429\n",
      "Epoch 110/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.1421 - accuracy: 0.9449\n",
      "Epoch 111/150\n",
      "54/54 [==============================] - 0s 887us/step - loss: 0.1420 - accuracy: 0.9443\n",
      "Epoch 112/150\n",
      "54/54 [==============================] - 0s 923us/step - loss: 0.1419 - accuracy: 0.9432\n",
      "Epoch 113/150\n",
      "54/54 [==============================] - 0s 942us/step - loss: 0.1418 - accuracy: 0.9441\n",
      "Epoch 114/150\n",
      "54/54 [==============================] - 0s 997us/step - loss: 0.1413 - accuracy: 0.9443\n",
      "Epoch 115/150\n",
      "54/54 [==============================] - 0s 887us/step - loss: 0.1411 - accuracy: 0.9452\n",
      "Epoch 116/150\n",
      "54/54 [==============================] - 0s 868us/step - loss: 0.1408 - accuracy: 0.9461\n",
      "Epoch 117/150\n",
      "54/54 [==============================] - 0s 979us/step - loss: 0.1407 - accuracy: 0.9452\n",
      "Epoch 118/150\n",
      "54/54 [==============================] - 0s 924us/step - loss: 0.1406 - accuracy: 0.9435\n",
      "Epoch 119/150\n",
      "54/54 [==============================] - 0s 942us/step - loss: 0.1402 - accuracy: 0.9461\n",
      "Epoch 120/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9449\n",
      "Epoch 121/150\n",
      "54/54 [==============================] - 0s 915us/step - loss: 0.1401 - accuracy: 0.9449\n",
      "Epoch 122/150\n",
      "54/54 [==============================] - 0s 923us/step - loss: 0.1396 - accuracy: 0.9464\n",
      "Epoch 123/150\n",
      "54/54 [==============================] - 0s 921us/step - loss: 0.1396 - accuracy: 0.9441\n",
      "Epoch 124/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.9470\n",
      "Epoch 125/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1395 - accuracy: 0.9443\n",
      "Epoch 126/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9461\n",
      "Epoch 127/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9461\n",
      "Epoch 128/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9452\n",
      "Epoch 129/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1384 - accuracy: 0.9458\n",
      "Epoch 130/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1384 - accuracy: 0.9470\n",
      "Epoch 131/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1383 - accuracy: 0.9458\n",
      "Epoch 132/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1381 - accuracy: 0.9467\n",
      "Epoch 133/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1381 - accuracy: 0.9472\n",
      "Epoch 134/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.9472\n",
      "Epoch 135/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9458\n",
      "Epoch 136/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1377 - accuracy: 0.9464\n",
      "Epoch 137/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9470\n",
      "Epoch 138/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9461\n",
      "Epoch 139/150\n",
      "54/54 [==============================] - 0s 960us/step - loss: 0.1372 - accuracy: 0.9470\n",
      "Epoch 140/150\n",
      "54/54 [==============================] - 0s 923us/step - loss: 0.1376 - accuracy: 0.9470\n",
      "Epoch 141/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.1372 - accuracy: 0.9478\n",
      "Epoch 142/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.1371 - accuracy: 0.9481\n",
      "Epoch 143/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.1368 - accuracy: 0.9478\n",
      "Epoch 144/150\n",
      "54/54 [==============================] - 0s 979us/step - loss: 0.1365 - accuracy: 0.9478\n",
      "Epoch 145/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.1366 - accuracy: 0.9475\n",
      "Epoch 146/150\n",
      "54/54 [==============================] - 0s 886us/step - loss: 0.1362 - accuracy: 0.9470\n",
      "Epoch 147/150\n",
      "54/54 [==============================] - 0s 960us/step - loss: 0.1365 - accuracy: 0.9481\n",
      "Epoch 148/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.9467\n",
      "Epoch 149/150\n",
      "54/54 [==============================] - 0s 951us/step - loss: 0.1361 - accuracy: 0.9478\n",
      "Epoch 150/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20e241d5dc0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rede Neural Simples\n",
    "train_y_array = np.array(train_y)\n",
    "val_y_array = np.array(val_y)\n",
    "\n",
    "# define the keras model\n",
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(3, input_dim=train_X.shape[1], activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_NN = KerasClassifier(build_fn=base_model, epochs=150, batch_size=64)    \n",
    "model_NN.fit(X_train_scale, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9287576020851434"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_NN.predict(val_X_scale)\n",
    "accuracy_score(val_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0386\n",
       "                \n",
       "                    &plusmn; 0.0084\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_hp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.14%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0302\n",
       "                \n",
       "                    &plusmn; 0.0104\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                char_freq_exclamation\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0269\n",
       "                \n",
       "                    &plusmn; 0.0111\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                char_freq_dollar\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.60%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0173\n",
       "                \n",
       "                    &plusmn; 0.0092\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_remove\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0169\n",
       "                \n",
       "                    &plusmn; 0.0049\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_george\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.34%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0136\n",
       "                \n",
       "                    &plusmn; 0.0057\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_000\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0126\n",
       "                \n",
       "                    &plusmn; 0.0077\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_free\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0108\n",
       "                \n",
       "                    &plusmn; 0.0049\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_85\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.33%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "                    &plusmn; 0.0043\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_money\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0096\n",
       "                \n",
       "                    &plusmn; 0.0065\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_hpl\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.46%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0078\n",
       "                \n",
       "                    &plusmn; 0.0038\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_meeting\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.13%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_650\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0057\n",
       "                \n",
       "                    &plusmn; 0.0045\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_cs\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.79%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0056\n",
       "                \n",
       "                    &plusmn; 0.0072\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                capital_run_length_longest\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0049\n",
       "                \n",
       "                    &plusmn; 0.0034\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_receive\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0047\n",
       "                \n",
       "                    &plusmn; 0.0047\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_addresses\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0045\n",
       "                \n",
       "                    &plusmn; 0.0024\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_415\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.66%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0043\n",
       "                \n",
       "                    &plusmn; 0.0047\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_credit\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.97%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0039\n",
       "                \n",
       "                    &plusmn; 0.0050\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_edu\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0036\n",
       "                \n",
       "                    &plusmn; 0.0033\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                word_freq_business\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.23%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 37 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(model_NN, scoring = 'accuracy', cv = 'prefit', n_iter = 10)\n",
    "perm.fit(val_X_scale, val_y_array)\n",
    "eli5.show_weights(perm, feature_names = val_X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>features_importances</th>\n",
       "      <th>features_standard_deviations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word_freq_make</td>\n",
       "      <td>-8.688097e-05</td>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word_freq_address</td>\n",
       "      <td>1.476977e-03</td>\n",
       "      <td>0.001032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word_freq_all</td>\n",
       "      <td>-2.432667e-03</td>\n",
       "      <td>0.001390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>word_freq_3d</td>\n",
       "      <td>1.303215e-03</td>\n",
       "      <td>0.000583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word_freq_our</td>\n",
       "      <td>2.693310e-03</td>\n",
       "      <td>0.002532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>word_freq_over</td>\n",
       "      <td>8.688097e-04</td>\n",
       "      <td>0.001401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>word_freq_remove</td>\n",
       "      <td>1.728931e-02</td>\n",
       "      <td>0.004605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>word_freq_internet</td>\n",
       "      <td>2.519548e-03</td>\n",
       "      <td>0.001527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>word_freq_order</td>\n",
       "      <td>1.303215e-03</td>\n",
       "      <td>0.001467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>word_freq_mail</td>\n",
       "      <td>-8.688097e-05</td>\n",
       "      <td>0.002036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>word_freq_receive</td>\n",
       "      <td>4.865334e-03</td>\n",
       "      <td>0.001703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>word_freq_will</td>\n",
       "      <td>3.388358e-03</td>\n",
       "      <td>0.001371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>word_freq_people</td>\n",
       "      <td>3.475239e-04</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>word_freq_report</td>\n",
       "      <td>1.824500e-03</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>word_freq_addresses</td>\n",
       "      <td>4.691573e-03</td>\n",
       "      <td>0.002370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>word_freq_free</td>\n",
       "      <td>1.259774e-02</td>\n",
       "      <td>0.003871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>word_freq_business</td>\n",
       "      <td>3.562120e-03</td>\n",
       "      <td>0.001669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>word_freq_email</td>\n",
       "      <td>8.688097e-05</td>\n",
       "      <td>0.002213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>word_freq_you</td>\n",
       "      <td>3.040834e-03</td>\n",
       "      <td>0.001467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>word_freq_credit</td>\n",
       "      <td>4.344049e-03</td>\n",
       "      <td>0.002363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>word_freq_your</td>\n",
       "      <td>3.475239e-03</td>\n",
       "      <td>0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>word_freq_font</td>\n",
       "      <td>5.212858e-04</td>\n",
       "      <td>0.001113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>word_freq_000</td>\n",
       "      <td>1.364031e-02</td>\n",
       "      <td>0.002857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>word_freq_money</td>\n",
       "      <td>9.817550e-03</td>\n",
       "      <td>0.002165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>word_freq_hp</td>\n",
       "      <td>3.857515e-02</td>\n",
       "      <td>0.004224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>word_freq_hpl</td>\n",
       "      <td>9.643788e-03</td>\n",
       "      <td>0.003261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>word_freq_george</td>\n",
       "      <td>1.685491e-02</td>\n",
       "      <td>0.002464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>word_freq_650</td>\n",
       "      <td>6.689835e-03</td>\n",
       "      <td>0.004094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>word_freq_lab</td>\n",
       "      <td>2.432667e-03</td>\n",
       "      <td>0.002357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>word_freq_labs</td>\n",
       "      <td>4.344049e-04</td>\n",
       "      <td>0.001182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>word_freq_telnet</td>\n",
       "      <td>2.606429e-03</td>\n",
       "      <td>0.002128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>word_freq_857</td>\n",
       "      <td>1.824500e-03</td>\n",
       "      <td>0.001960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>word_freq_data</td>\n",
       "      <td>1.390096e-03</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>word_freq_415</td>\n",
       "      <td>4.517811e-03</td>\n",
       "      <td>0.001216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>word_freq_85</td>\n",
       "      <td>1.077324e-02</td>\n",
       "      <td>0.002433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>word_freq_technology</td>\n",
       "      <td>1.303215e-03</td>\n",
       "      <td>0.001116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>word_freq_1999</td>\n",
       "      <td>1.650738e-03</td>\n",
       "      <td>0.002281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>word_freq_parts</td>\n",
       "      <td>1.650738e-03</td>\n",
       "      <td>0.001061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>word_freq_pm</td>\n",
       "      <td>-1.042572e-03</td>\n",
       "      <td>0.001013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>word_freq_direct</td>\n",
       "      <td>-1.563858e-03</td>\n",
       "      <td>0.000936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>word_freq_cs</td>\n",
       "      <td>5.734144e-03</td>\n",
       "      <td>0.002239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>word_freq_meeting</td>\n",
       "      <td>7.819288e-03</td>\n",
       "      <td>0.001903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>word_freq_original</td>\n",
       "      <td>8.688097e-04</td>\n",
       "      <td>0.001229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>word_freq_project</td>\n",
       "      <td>3.127715e-03</td>\n",
       "      <td>0.001658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>word_freq_re</td>\n",
       "      <td>2.867072e-03</td>\n",
       "      <td>0.001557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>word_freq_edu</td>\n",
       "      <td>3.909644e-03</td>\n",
       "      <td>0.002495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>word_freq_table</td>\n",
       "      <td>1.129453e-03</td>\n",
       "      <td>0.000556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>word_freq_conference</td>\n",
       "      <td>4.344049e-04</td>\n",
       "      <td>0.001913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>char_freq_comma</td>\n",
       "      <td>2.606429e-03</td>\n",
       "      <td>0.001454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>char_freq_parentheses</td>\n",
       "      <td>-1.110223e-17</td>\n",
       "      <td>0.000869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>char_freq_key</td>\n",
       "      <td>-1.737619e-04</td>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>char_freq_exclamation</td>\n",
       "      <td>3.023458e-02</td>\n",
       "      <td>0.005210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>char_freq_dollar</td>\n",
       "      <td>2.693310e-02</td>\n",
       "      <td>0.005563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>char_freq_hashtag</td>\n",
       "      <td>9.556907e-04</td>\n",
       "      <td>0.001477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>capital_run_length_average</td>\n",
       "      <td>7.819288e-04</td>\n",
       "      <td>0.001477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>capital_run_length_longest</td>\n",
       "      <td>5.647263e-03</td>\n",
       "      <td>0.003608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>capital_run_length_total</td>\n",
       "      <td>1.563858e-03</td>\n",
       "      <td>0.001974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      features  features_importances  \\\n",
       "0               word_freq_make         -8.688097e-05   \n",
       "1            word_freq_address          1.476977e-03   \n",
       "2                word_freq_all         -2.432667e-03   \n",
       "3                 word_freq_3d          1.303215e-03   \n",
       "4                word_freq_our          2.693310e-03   \n",
       "5               word_freq_over          8.688097e-04   \n",
       "6             word_freq_remove          1.728931e-02   \n",
       "7           word_freq_internet          2.519548e-03   \n",
       "8              word_freq_order          1.303215e-03   \n",
       "9               word_freq_mail         -8.688097e-05   \n",
       "10           word_freq_receive          4.865334e-03   \n",
       "11              word_freq_will          3.388358e-03   \n",
       "12            word_freq_people          3.475239e-04   \n",
       "13            word_freq_report          1.824500e-03   \n",
       "14         word_freq_addresses          4.691573e-03   \n",
       "15              word_freq_free          1.259774e-02   \n",
       "16          word_freq_business          3.562120e-03   \n",
       "17             word_freq_email          8.688097e-05   \n",
       "18               word_freq_you          3.040834e-03   \n",
       "19            word_freq_credit          4.344049e-03   \n",
       "20              word_freq_your          3.475239e-03   \n",
       "21              word_freq_font          5.212858e-04   \n",
       "22               word_freq_000          1.364031e-02   \n",
       "23             word_freq_money          9.817550e-03   \n",
       "24                word_freq_hp          3.857515e-02   \n",
       "25               word_freq_hpl          9.643788e-03   \n",
       "26            word_freq_george          1.685491e-02   \n",
       "27               word_freq_650          6.689835e-03   \n",
       "28               word_freq_lab          2.432667e-03   \n",
       "29              word_freq_labs          4.344049e-04   \n",
       "30            word_freq_telnet          2.606429e-03   \n",
       "31               word_freq_857          1.824500e-03   \n",
       "32              word_freq_data          1.390096e-03   \n",
       "33               word_freq_415          4.517811e-03   \n",
       "34                word_freq_85          1.077324e-02   \n",
       "35        word_freq_technology          1.303215e-03   \n",
       "36              word_freq_1999          1.650738e-03   \n",
       "37             word_freq_parts          1.650738e-03   \n",
       "38                word_freq_pm         -1.042572e-03   \n",
       "39            word_freq_direct         -1.563858e-03   \n",
       "40                word_freq_cs          5.734144e-03   \n",
       "41           word_freq_meeting          7.819288e-03   \n",
       "42          word_freq_original          8.688097e-04   \n",
       "43           word_freq_project          3.127715e-03   \n",
       "44                word_freq_re          2.867072e-03   \n",
       "45               word_freq_edu          3.909644e-03   \n",
       "46             word_freq_table          1.129453e-03   \n",
       "47        word_freq_conference          4.344049e-04   \n",
       "48             char_freq_comma          2.606429e-03   \n",
       "49       char_freq_parentheses         -1.110223e-17   \n",
       "50               char_freq_key         -1.737619e-04   \n",
       "51       char_freq_exclamation          3.023458e-02   \n",
       "52            char_freq_dollar          2.693310e-02   \n",
       "53           char_freq_hashtag          9.556907e-04   \n",
       "54  capital_run_length_average          7.819288e-04   \n",
       "55  capital_run_length_longest          5.647263e-03   \n",
       "56    capital_run_length_total          1.563858e-03   \n",
       "\n",
       "    features_standard_deviations  \n",
       "0                       0.000722  \n",
       "1                       0.001032  \n",
       "2                       0.001390  \n",
       "3                       0.000583  \n",
       "4                       0.002532  \n",
       "5                       0.001401  \n",
       "6                       0.004605  \n",
       "7                       0.001527  \n",
       "8                       0.001467  \n",
       "9                       0.002036  \n",
       "10                      0.001703  \n",
       "11                      0.001371  \n",
       "12                      0.001300  \n",
       "13                      0.000987  \n",
       "14                      0.002370  \n",
       "15                      0.003871  \n",
       "16                      0.001669  \n",
       "17                      0.002213  \n",
       "18                      0.001467  \n",
       "19                      0.002363  \n",
       "20                      0.002984  \n",
       "21                      0.001113  \n",
       "22                      0.002857  \n",
       "23                      0.002165  \n",
       "24                      0.004224  \n",
       "25                      0.003261  \n",
       "26                      0.002464  \n",
       "27                      0.004094  \n",
       "28                      0.002357  \n",
       "29                      0.001182  \n",
       "30                      0.002128  \n",
       "31                      0.001960  \n",
       "32                      0.001300  \n",
       "33                      0.001216  \n",
       "34                      0.002433  \n",
       "35                      0.001116  \n",
       "36                      0.002281  \n",
       "37                      0.001061  \n",
       "38                      0.001013  \n",
       "39                      0.000936  \n",
       "40                      0.002239  \n",
       "41                      0.001903  \n",
       "42                      0.001229  \n",
       "43                      0.001658  \n",
       "44                      0.001557  \n",
       "45                      0.002495  \n",
       "46                      0.000556  \n",
       "47                      0.001913  \n",
       "48                      0.001454  \n",
       "49                      0.000869  \n",
       "50                      0.001153  \n",
       "51                      0.005210  \n",
       "52                      0.005563  \n",
       "53                      0.001477  \n",
       "54                      0.001477  \n",
       "55                      0.003608  \n",
       "56                      0.001974  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'features' : val_X.columns.tolist(), \n",
    "     'features_importances': perm.feature_importances_.tolist(),\n",
    "     'features_standard_deviations': perm.feature_importances_std_.tolist()}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-8.688097306688291e-05,\n",
       " 0.0014769765421372648,\n",
       " -0.0024326672458731434,\n",
       " 0.0013032145960034768,\n",
       " 0.002693310165073848,\n",
       " 0.0008688097306689846,\n",
       " 0.017289313640312776,\n",
       " 0.002519548218940071,\n",
       " 0.0013032145960034768,\n",
       " -8.688097306690512e-05,\n",
       " 0.004865334491746309,\n",
       " 0.003388357949609033,\n",
       " 0.0003475238922676094,\n",
       " 0.0018245004344048632,\n",
       " 0.004691572545612488,\n",
       " 0.012597741094700243,\n",
       " 0.0035621198957428435,\n",
       " 8.688097306689402e-05,\n",
       " 0.003040834057341435,\n",
       " 0.004344048653344912,\n",
       " 0.0034752389226759273,\n",
       " 0.0005212858384013753,\n",
       " 0.013640312771503038,\n",
       " 0.009817549956559512,\n",
       " 0.038575152041702865,\n",
       " 0.009643788010425713,\n",
       " 0.016854908774978285,\n",
       " 0.006689834926151173,\n",
       " 0.0024326672458731434,\n",
       " 0.0004344048653344812,\n",
       " 0.002606429192006943,\n",
       " 0.001824500434404852,\n",
       " 0.0013900955690703486,\n",
       " 0.0045178105994787224,\n",
       " 0.010773240660295402,\n",
       " 0.0013032145960034768,\n",
       " 0.001650738488271053,\n",
       " 0.001650738488271053,\n",
       " -0.0010425716768027837,\n",
       " -0.00156385751520417,\n",
       " 0.005734144222415294,\n",
       " 0.007819287576020828,\n",
       " 0.0008688097306689624,\n",
       " 0.003127715030408362,\n",
       " 0.002867072111207658,\n",
       " 0.003909643788010409,\n",
       " 0.0011294526498696444,\n",
       " 0.0004344048653344812,\n",
       " 0.0026064291920069537,\n",
       " -1.1102230246251566e-17,\n",
       " -0.00017376194613379913,\n",
       " 0.03023457862728064,\n",
       " 0.02693310165073849,\n",
       " 0.0009556907037358786,\n",
       " 0.0007819287576020905,\n",
       " 0.0056472632493483775,\n",
       " 0.00156385751520417]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm.feature_importances_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_important = ['word_freq_make', \n",
    "         'char_freq_dollar',\n",
    "         'char_freq_exclamation',\n",
    "         'word_freq_remove', \n",
    "         'word_freq_000',\n",
    "         'word_freq_edu',\n",
    "         'capital_run_length_longest']\n",
    "X_train_scale_important = scaler.fit_transform(train_X[vars_important])\n",
    "val_X_scale_important = scaler.fit_transform(val_X[vars_important])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "54/54 [==============================] - 0s 850us/step - loss: 0.6290 - accuracy: 0.7525\n",
      "Epoch 2/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.7684\n",
      "Epoch 3/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.5527 - accuracy: 0.7829\n",
      "Epoch 4/150\n",
      "54/54 [==============================] - 0s 776us/step - loss: 0.5204 - accuracy: 0.7901\n",
      "Epoch 5/150\n",
      "54/54 [==============================] - 0s 887us/step - loss: 0.4924 - accuracy: 0.7974\n",
      "Epoch 6/150\n",
      "54/54 [==============================] - 0s 868us/step - loss: 0.4691 - accuracy: 0.8029\n",
      "Epoch 7/150\n",
      "54/54 [==============================] - 0s 812us/step - loss: 0.4497 - accuracy: 0.8101\n",
      "Epoch 8/150\n",
      "54/54 [==============================] - 0s 850us/step - loss: 0.4342 - accuracy: 0.8142\n",
      "Epoch 9/150\n",
      "54/54 [==============================] - 0s 942us/step - loss: 0.4219 - accuracy: 0.8200\n",
      "Epoch 10/150\n",
      "54/54 [==============================] - 0s 776us/step - loss: 0.4114 - accuracy: 0.8249\n",
      "Epoch 11/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4024 - accuracy: 0.8307\n",
      "Epoch 12/150\n",
      "54/54 [==============================] - 0s 979us/step - loss: 0.3944 - accuracy: 0.8348\n",
      "Epoch 13/150\n",
      "54/54 [==============================] - 0s 776us/step - loss: 0.3871 - accuracy: 0.8412\n",
      "Epoch 14/150\n",
      "54/54 [==============================] - 0s 850us/step - loss: 0.3798 - accuracy: 0.8478\n",
      "Epoch 15/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3729 - accuracy: 0.8522\n",
      "Epoch 16/150\n",
      "54/54 [==============================] - 0s 842us/step - loss: 0.3661 - accuracy: 0.8551\n",
      "Epoch 17/150\n",
      "54/54 [==============================] - 0s 776us/step - loss: 0.3593 - accuracy: 0.8597\n",
      "Epoch 18/150\n",
      "54/54 [==============================] - 0s 833us/step - loss: 0.3528 - accuracy: 0.8629\n",
      "Epoch 19/150\n",
      "54/54 [==============================] - 0s 831us/step - loss: 0.3473 - accuracy: 0.8672\n",
      "Epoch 20/150\n",
      "54/54 [==============================] - 0s 868us/step - loss: 0.3425 - accuracy: 0.8701\n",
      "Epoch 21/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8707\n",
      "Epoch 22/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8742\n",
      "Epoch 23/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.3324 - accuracy: 0.8765\n",
      "Epoch 24/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.3301 - accuracy: 0.8771\n",
      "Epoch 25/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8783\n",
      "Epoch 26/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8791\n",
      "Epoch 27/150\n",
      "54/54 [==============================] - 0s 997us/step - loss: 0.3241 - accuracy: 0.8806\n",
      "Epoch 28/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8823\n",
      "Epoch 29/150\n",
      "54/54 [==============================] - 0s 886us/step - loss: 0.3208 - accuracy: 0.8832\n",
      "Epoch 30/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.3191 - accuracy: 0.8832\n",
      "Epoch 31/150\n",
      "54/54 [==============================] - 0s 794us/step - loss: 0.3179 - accuracy: 0.8829\n",
      "Epoch 32/150\n",
      "54/54 [==============================] - 0s 739us/step - loss: 0.3166 - accuracy: 0.8835\n",
      "Epoch 33/150\n",
      "54/54 [==============================] - 0s 831us/step - loss: 0.3153 - accuracy: 0.8835\n",
      "Epoch 34/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.3142 - accuracy: 0.8829\n",
      "Epoch 35/150\n",
      "54/54 [==============================] - 0s 914us/step - loss: 0.3132 - accuracy: 0.8820\n",
      "Epoch 36/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3122 - accuracy: 0.8820\n",
      "Epoch 37/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3112 - accuracy: 0.8823\n",
      "Epoch 38/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3103 - accuracy: 0.8820\n",
      "Epoch 39/150\n",
      "54/54 [==============================] - 0s 997us/step - loss: 0.3095 - accuracy: 0.8829\n",
      "Epoch 40/150\n",
      "54/54 [==============================] - 0s 770us/step - loss: 0.3087 - accuracy: 0.8835\n",
      "Epoch 41/150\n",
      "54/54 [==============================] - 0s 886us/step - loss: 0.3080 - accuracy: 0.8852\n",
      "Epoch 42/150\n",
      "54/54 [==============================] - 0s 868us/step - loss: 0.3073 - accuracy: 0.8843\n",
      "Epoch 43/150\n",
      "54/54 [==============================] - 0s 960us/step - loss: 0.3065 - accuracy: 0.8849\n",
      "Epoch 44/150\n",
      "54/54 [==============================] - 0s 923us/step - loss: 0.3060 - accuracy: 0.8835\n",
      "Epoch 45/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.3054 - accuracy: 0.8864\n",
      "Epoch 46/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3049 - accuracy: 0.8870\n",
      "Epoch 47/150\n",
      "54/54 [==============================] - 0s 850us/step - loss: 0.3044 - accuracy: 0.8878\n",
      "Epoch 48/150\n",
      "54/54 [==============================] - 0s 757us/step - loss: 0.3039 - accuracy: 0.8890\n",
      "Epoch 49/150\n",
      "54/54 [==============================] - 0s 776us/step - loss: 0.3034 - accuracy: 0.8881\n",
      "Epoch 50/150\n",
      "54/54 [==============================] - 0s 831us/step - loss: 0.3030 - accuracy: 0.8901\n",
      "Epoch 51/150\n",
      "54/54 [==============================] - 0s 850us/step - loss: 0.3026 - accuracy: 0.8884\n",
      "Epoch 52/150\n",
      "54/54 [==============================] - 0s 794us/step - loss: 0.3021 - accuracy: 0.8893\n",
      "Epoch 53/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.3017 - accuracy: 0.8904\n",
      "Epoch 54/150\n",
      "54/54 [==============================] - 0s 813us/step - loss: 0.3013 - accuracy: 0.8913\n",
      "Epoch 55/150\n",
      "54/54 [==============================] - 0s 831us/step - loss: 0.3011 - accuracy: 0.8907\n",
      "Epoch 56/150\n",
      "54/54 [==============================] - 0s 923us/step - loss: 0.3006 - accuracy: 0.8913\n",
      "Epoch 57/150\n",
      "54/54 [==============================] - 0s 923us/step - loss: 0.3004 - accuracy: 0.8913\n",
      "Epoch 58/150\n",
      "54/54 [==============================] - 0s 923us/step - loss: 0.3000 - accuracy: 0.8919\n",
      "Epoch 59/150\n",
      "54/54 [==============================] - 0s 776us/step - loss: 0.2998 - accuracy: 0.8922\n",
      "Epoch 60/150\n",
      "54/54 [==============================] - 0s 776us/step - loss: 0.2995 - accuracy: 0.8922\n",
      "Epoch 61/150\n",
      "54/54 [==============================] - 0s 794us/step - loss: 0.2993 - accuracy: 0.8925\n",
      "Epoch 62/150\n",
      "54/54 [==============================] - 0s 739us/step - loss: 0.2991 - accuracy: 0.8919\n",
      "Epoch 63/150\n",
      "54/54 [==============================] - 0s 813us/step - loss: 0.2988 - accuracy: 0.8919\n",
      "Epoch 64/150\n",
      "54/54 [==============================] - 0s 813us/step - loss: 0.2986 - accuracy: 0.8942\n",
      "Epoch 65/150\n",
      "54/54 [==============================] - 0s 794us/step - loss: 0.2982 - accuracy: 0.8942\n",
      "Epoch 66/150\n",
      "54/54 [==============================] - 0s 812us/step - loss: 0.2980 - accuracy: 0.8939\n",
      "Epoch 67/150\n",
      "54/54 [==============================] - 0s 831us/step - loss: 0.2978 - accuracy: 0.8942\n",
      "Epoch 68/150\n",
      "54/54 [==============================] - 0s 794us/step - loss: 0.2976 - accuracy: 0.8942\n",
      "Epoch 69/150\n",
      "54/54 [==============================] - 0s 813us/step - loss: 0.2977 - accuracy: 0.8939\n",
      "Epoch 70/150\n",
      "54/54 [==============================] - 0s 813us/step - loss: 0.2972 - accuracy: 0.8939\n",
      "Epoch 71/150\n",
      "54/54 [==============================] - 0s 739us/step - loss: 0.2971 - accuracy: 0.8942\n",
      "Epoch 72/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.8939\n",
      "Epoch 73/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2967 - accuracy: 0.8933\n",
      "Epoch 74/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.8933\n",
      "Epoch 75/150\n",
      "54/54 [==============================] - 0s 831us/step - loss: 0.2962 - accuracy: 0.8936\n",
      "Epoch 76/150\n",
      "54/54 [==============================] - 0s 813us/step - loss: 0.2960 - accuracy: 0.8930\n",
      "Epoch 77/150\n",
      "54/54 [==============================] - 0s 794us/step - loss: 0.2958 - accuracy: 0.8933\n",
      "Epoch 78/150\n",
      "54/54 [==============================] - 0s 905us/step - loss: 0.2956 - accuracy: 0.8936\n",
      "Epoch 79/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2955 - accuracy: 0.8933\n",
      "Epoch 80/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2954 - accuracy: 0.8936\n",
      "Epoch 81/150\n",
      "54/54 [==============================] - 0s 979us/step - loss: 0.2951 - accuracy: 0.8930\n",
      "Epoch 82/150\n",
      "54/54 [==============================] - 0s 813us/step - loss: 0.2949 - accuracy: 0.8933\n",
      "Epoch 83/150\n",
      "54/54 [==============================] - 0s 794us/step - loss: 0.2948 - accuracy: 0.8933\n",
      "Epoch 84/150\n",
      "54/54 [==============================] - 0s 868us/step - loss: 0.2946 - accuracy: 0.8933\n",
      "Epoch 85/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2945 - accuracy: 0.8933\n",
      "Epoch 86/150\n",
      "54/54 [==============================] - 0s 979us/step - loss: 0.2944 - accuracy: 0.8933\n",
      "Epoch 87/150\n",
      "54/54 [==============================] - 0s 831us/step - loss: 0.2942 - accuracy: 0.8928\n",
      "Epoch 88/150\n",
      "54/54 [==============================] - 0s 739us/step - loss: 0.2940 - accuracy: 0.8930\n",
      "Epoch 89/150\n",
      "54/54 [==============================] - 0s 739us/step - loss: 0.2939 - accuracy: 0.8928\n",
      "Epoch 90/150\n",
      "54/54 [==============================] - 0s 923us/step - loss: 0.2938 - accuracy: 0.8933\n",
      "Epoch 91/150\n",
      "54/54 [==============================] - 0s 776us/step - loss: 0.2936 - accuracy: 0.8933\n",
      "Epoch 92/150\n",
      "54/54 [==============================] - 0s 720us/step - loss: 0.2935 - accuracy: 0.8933\n",
      "Epoch 93/150\n",
      "54/54 [==============================] - 0s 757us/step - loss: 0.2934 - accuracy: 0.8930\n",
      "Epoch 94/150\n",
      "54/54 [==============================] - 0s 776us/step - loss: 0.2934 - accuracy: 0.8930\n",
      "Epoch 95/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2932 - accuracy: 0.8936\n",
      "Epoch 96/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2931 - accuracy: 0.8936\n",
      "Epoch 97/150\n",
      "54/54 [==============================] - 0s 979us/step - loss: 0.2930 - accuracy: 0.8933\n",
      "Epoch 98/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2928 - accuracy: 0.8936\n",
      "Epoch 99/150\n",
      "54/54 [==============================] - 0s 953us/step - loss: 0.2928 - accuracy: 0.8936\n",
      "Epoch 100/150\n",
      "54/54 [==============================] - 0s 794us/step - loss: 0.2926 - accuracy: 0.8933\n",
      "Epoch 101/150\n",
      "54/54 [==============================] - 0s 757us/step - loss: 0.2926 - accuracy: 0.8928\n",
      "Epoch 102/150\n",
      "54/54 [==============================] - 0s 813us/step - loss: 0.2924 - accuracy: 0.8942\n",
      "Epoch 103/150\n",
      "54/54 [==============================] - 0s 794us/step - loss: 0.2926 - accuracy: 0.8930\n",
      "Epoch 104/150\n",
      "54/54 [==============================] - 0s 776us/step - loss: 0.2923 - accuracy: 0.8942\n",
      "Epoch 105/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2923 - accuracy: 0.8936\n",
      "Epoch 106/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2921 - accuracy: 0.8936\n",
      "Epoch 107/150\n",
      "54/54 [==============================] - 0s 813us/step - loss: 0.2919 - accuracy: 0.8936\n",
      "Epoch 108/150\n",
      "54/54 [==============================] - 0s 739us/step - loss: 0.2919 - accuracy: 0.8939\n",
      "Epoch 109/150\n",
      "54/54 [==============================] - 0s 739us/step - loss: 0.2918 - accuracy: 0.8930\n",
      "Epoch 110/150\n",
      "54/54 [==============================] - 0s 776us/step - loss: 0.2916 - accuracy: 0.8936\n",
      "Epoch 111/150\n",
      "54/54 [==============================] - 0s 702us/step - loss: 0.2912 - accuracy: 0.8936\n",
      "Epoch 112/150\n",
      "54/54 [==============================] - 0s 757us/step - loss: 0.2910 - accuracy: 0.8939\n",
      "Epoch 113/150\n",
      "54/54 [==============================] - 0s 776us/step - loss: 0.2911 - accuracy: 0.8942\n",
      "Epoch 114/150\n",
      "54/54 [==============================] - 0s 720us/step - loss: 0.2909 - accuracy: 0.8939\n",
      "Epoch 115/150\n",
      "54/54 [==============================] - 0s 720us/step - loss: 0.2909 - accuracy: 0.8945\n",
      "Epoch 116/150\n",
      "54/54 [==============================] - 0s 757us/step - loss: 0.2907 - accuracy: 0.8942\n",
      "Epoch 117/150\n",
      "54/54 [==============================] - 0s 739us/step - loss: 0.2906 - accuracy: 0.8942\n",
      "Epoch 118/150\n",
      "54/54 [==============================] - 0s 794us/step - loss: 0.2906 - accuracy: 0.8939\n",
      "Epoch 119/150\n",
      "54/54 [==============================] - 0s 739us/step - loss: 0.2905 - accuracy: 0.8936\n",
      "Epoch 120/150\n",
      "54/54 [==============================] - 0s 757us/step - loss: 0.2904 - accuracy: 0.8933\n",
      "Epoch 121/150\n",
      "54/54 [==============================] - 0s 776us/step - loss: 0.2904 - accuracy: 0.8939\n",
      "Epoch 122/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2902 - accuracy: 0.8945\n",
      "Epoch 123/150\n",
      "54/54 [==============================] - 0s 757us/step - loss: 0.2902 - accuracy: 0.8936\n",
      "Epoch 124/150\n",
      "54/54 [==============================] - 0s 739us/step - loss: 0.2900 - accuracy: 0.8942\n",
      "Epoch 125/150\n",
      "54/54 [==============================] - 0s 868us/step - loss: 0.2900 - accuracy: 0.8939\n",
      "Epoch 126/150\n",
      "54/54 [==============================] - 0s 868us/step - loss: 0.2900 - accuracy: 0.8936\n",
      "Epoch 127/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2898 - accuracy: 0.8936\n",
      "Epoch 128/150\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8936\n",
      "Epoch 129/150\n",
      "54/54 [==============================] - 0s 739us/step - loss: 0.2897 - accuracy: 0.8930\n",
      "Epoch 130/150\n",
      "54/54 [==============================] - 0s 776us/step - loss: 0.2898 - accuracy: 0.8928\n",
      "Epoch 131/150\n",
      "54/54 [==============================] - 0s 720us/step - loss: 0.2896 - accuracy: 0.8933\n",
      "Epoch 132/150\n",
      "54/54 [==============================] - 0s 794us/step - loss: 0.2895 - accuracy: 0.8942\n",
      "Epoch 133/150\n",
      "54/54 [==============================] - 0s 757us/step - loss: 0.2895 - accuracy: 0.8933\n",
      "Epoch 134/150\n",
      "54/54 [==============================] - 0s 942us/step - loss: 0.2895 - accuracy: 0.8942\n",
      "Epoch 135/150\n",
      "54/54 [==============================] - 0s 960us/step - loss: 0.2893 - accuracy: 0.8945\n",
      "Epoch 136/150\n",
      "54/54 [==============================] - 0s 923us/step - loss: 0.2893 - accuracy: 0.8936\n",
      "Epoch 137/150\n",
      "54/54 [==============================] - 0s 776us/step - loss: 0.2894 - accuracy: 0.8939\n",
      "Epoch 138/150\n",
      "54/54 [==============================] - 0s 757us/step - loss: 0.2892 - accuracy: 0.8945\n",
      "Epoch 139/150\n",
      "54/54 [==============================] - 0s 813us/step - loss: 0.2892 - accuracy: 0.8939\n",
      "Epoch 140/150\n",
      "54/54 [==============================] - 0s 702us/step - loss: 0.2890 - accuracy: 0.8945\n",
      "Epoch 141/150\n",
      "54/54 [==============================] - 0s 960us/step - loss: 0.2890 - accuracy: 0.8954\n",
      "Epoch 142/150\n",
      "54/54 [==============================] - 0s 850us/step - loss: 0.2889 - accuracy: 0.8951\n",
      "Epoch 143/150\n",
      "54/54 [==============================] - 0s 739us/step - loss: 0.2888 - accuracy: 0.8939\n",
      "Epoch 144/150\n",
      "54/54 [==============================] - 0s 886us/step - loss: 0.2889 - accuracy: 0.8942\n",
      "Epoch 145/150\n",
      "54/54 [==============================] - 0s 868us/step - loss: 0.2888 - accuracy: 0.8942\n",
      "Epoch 146/150\n",
      "54/54 [==============================] - 0s 850us/step - loss: 0.2886 - accuracy: 0.8957\n",
      "Epoch 147/150\n",
      "54/54 [==============================] - 0s 850us/step - loss: 0.2886 - accuracy: 0.8945\n",
      "Epoch 148/150\n",
      "54/54 [==============================] - 0s 813us/step - loss: 0.2885 - accuracy: 0.8951\n",
      "Epoch 149/150\n",
      "54/54 [==============================] - 0s 868us/step - loss: 0.2887 - accuracy: 0.8959\n",
      "Epoch 150/150\n",
      "54/54 [==============================] - 0s 813us/step - loss: 0.2884 - accuracy: 0.8957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20e1d848fd0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the keras model\n",
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(3, input_dim=7, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_NN = KerasClassifier(build_fn=base_model, epochs=150, batch_size=64)    \n",
    "model_NN.fit(X_train_scale_important, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8844483058210252"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_NN.predict(val_X_scale_important)\n",
    "accuracy_score(val_y, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
